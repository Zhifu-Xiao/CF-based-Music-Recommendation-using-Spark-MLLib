{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# data preprocessing\n",
    "awk 'NF>=2' artist_alias.txt > artist_alias_new.txt\n",
    "awk '$1 + 0 !=S1 && NF>=2' artist_data.txt > artist_data_new.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Cent\n",
      "[unknown]\n",
      "Eminem\n",
      "Red Hot Chili Peppers\n",
      "Nirvana\n",
      "Outkast\n",
      "Linkin Park\n",
      "Green Day\n",
      "Gwen Stefani\n",
      "Beastie Boys\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *\n",
    "from pyspark import SparkContext\n",
    "# sc = SparkContext()\n",
    "\n",
    "# load raw data\n",
    "rawUserArtistData = sc.textFile(\"user_artist_data.txt\", use_unicode=False)\n",
    "rawArtistData = sc.textFile(\"artist_data_new.txt\", use_unicode=False)\n",
    "rawArtistAlias = sc.textFile(\"artist_alias_new.txt\", use_unicode=False)\n",
    "\n",
    "def getArtistByID(line):\n",
    "    try:\n",
    "        (artistID, name) = line.split('\\t',1)\n",
    "        artistID = int(artistID)\n",
    "    except:\n",
    "        return []\n",
    "    return [(artistID, name.strip())]\n",
    "\n",
    "artistByID = rawArtistData.flatMap(getArtistByID)\n",
    "\n",
    "artistAlias = rawArtistAlias.map(lambda x: x.split('\\t',1)).\\\n",
    "    map(lambda y: (int(y[0]), int(y[1]))).\\\n",
    "    collectAsMap()\n",
    "\n",
    "bArtistAlias = sc.broadcast(artistAlias)\n",
    "\n",
    "# generateRating\n",
    "def generateRating(line):\n",
    "    (userID, artistID, count) = line.split(' ')\n",
    "    userID = int(userID)\n",
    "    artistID = int(artistID)\n",
    "    count = int(count)\n",
    "    finalArtistID = bArtistAlias.value.get(artistID)\n",
    "    if not finalArtistID:\n",
    "        finalArtistID = artistID\n",
    "    finalArtistID = int(finalArtistID)\n",
    "    return Rating(userID, finalArtistID, count)\n",
    "    \n",
    "trainData = rawUserArtistData.map(generateRating).cache()\n",
    "\n",
    "# use best model from the book\n",
    "model = ALS.trainImplicit(trainData, rank=20, iterations=5, lambda_=1.0, alpha=40.0)\n",
    "\n",
    "# recommendProducts, code from \n",
    "# https://spark.apache.org/docs/latest/api/python/_modules/pyspark/mllib/recommendation.html\n",
    "def recommendProducts(self, user, num):\n",
    "    \"\"\"\n",
    "    Recommends the top \"num\" number of products for a given user and\n",
    "    returns a list of Rating objects sorted by the predicted rating in\n",
    "    descending order.\n",
    "    \"\"\"\n",
    "    return list(self.call(\"recommendProducts\", user, num))\n",
    "\n",
    "recommendations = recommendProducts(model, 2093760, 10)\n",
    "for i in recommendations: print i\n",
    "\n",
    "recommendedProductIDs = map(lambda (userID, productID, count): productID, recommendations)\n",
    "\n",
    "def getRecommendedIDs(line):\n",
    "    (artistID, name) = line\n",
    "    return artistID in recommendedProductIDs\n",
    "\n",
    "recommendedProducts = artistByID.filter(getRecommendedIDs).values().collect()\n",
    "for i in recommendedProducts: print i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
